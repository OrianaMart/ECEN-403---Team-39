{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ00Tad692JgOOuVOLsJpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrianaMart/ECEN-403---Team-39/blob/ML/TEAM39_MLModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6JAYE5jTosp"
      },
      "outputs": [],
      "source": [
        "!unzip DatasetV3.zip #This portion unzips the folder containing the dataset images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf DatasetV3/ #This is only to be run when the file needs to be cleared out"
      ],
      "metadata": {
        "id": "DHrFzUciN2Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf    #This section is where all the necessary imports are brought into the project\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RnTrUq9zUoYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.backend import set_session\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
        "config.gpu_options.visible_device_list = \"0\"\n",
        "\n",
        "set_session(tf.compat.v1.Session(config=config))\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xgsxx7nN1bFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#img_height, img_width = 64,64    #Sets constant image size\n",
        "#batch_size = 16      #Amount of images to be processed at a given time, the lower the number the easier it is to process\n",
        "\n",
        "#train_ds = tf.keras.utils.image_dataset_from_directory(          #Set up for the training dataset, takes image directory and turns it into a dataset\n",
        "    #\"DatasetV3/Training\",                                   #Sets training image directory to training dataset\n",
        "    #image_size = (img_height, img_width),                    #Constant image size that matches previously set size\n",
        "    #batch_size = batch_size                                       #Constant bach size\n",
        "#)\n",
        "#val_ds = tf.keras.utils.image_dataset_from_directory(       #Set up for the validation dataset, takes image directory and turns it into a dataset\n",
        "    #\"DatasetV3/Validation\",                                    #Sets validation image directory to validation dataset\n",
        "    #image_size = (img_height, img_width),                        #Constant image size that matches previously set size\n",
        "    #batch_size = batch_size                                              #Constant bach size\n",
        "#)\n",
        "#test_ds = tf.keras.utils.image_dataset_from_directory(       #Set up for the testing dataset, takes image directory and turns it into a dataset\n",
        "    #\"DatasetV3/Testing\",                                       #Sets testing image directory to testing dataset\n",
        "    #image_size = (img_height, img_width),                        #Constant image size that matches previously set size\n",
        "    #batch_size = batch_size                                     #Constant bach size\n",
        "#)"
      ],
      "metadata": {
        "id": "Jf3_3mybU0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 180,180\n",
        "image_size = (img_height, img_width)\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"DatasetV3\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "yzg63L9EnUY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter out corrupted images\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "num_skipped = 0\n",
        "\n",
        "for folder_name in (\"Battery\",\"Calculator\",\"Charger\",\"Jumper Wire\",\"LCD Screen\",\"LED\",\"MOSFET\",\"Microcontroller\",\"Resistor\",\"SD Card\",\"USB\"):\n",
        "    folder_path = os.path.join(\"DatasetV3\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        if fname.endswith('.jpg'):\n",
        "            try:\n",
        "                img = Image.open(fpath) # open the image file\n",
        "                #print(\"%s\", fpath)\n",
        "                exif_data = img._getexif()\n",
        "                img.verify() # verify that it is, in fact an image\n",
        "            except:\n",
        "                num_skipped += 1\n",
        "                # Delete corrupted image\n",
        "                os.remove(fpath)\n",
        "print(\"PIL deleted %d images\" % num_skipped)"
      ],
      "metadata": {
        "id": "T94RN7hqdP4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "def check_images( s_dir, ext_list):\n",
        "    bad_images=[]\n",
        "    bad_ext=[]\n",
        "    s_list= os.listdir(s_dir)\n",
        "    for klass in s_list:\n",
        "        klass_path=os.path.join (s_dir, klass)\n",
        "        print ('processing class directory ', klass)\n",
        "        if os.path.isdir(klass_path):\n",
        "            file_list=os.listdir(klass_path)\n",
        "            for f in file_list:\n",
        "                f_path=os.path.join (klass_path,f)\n",
        "                tip = imghdr.what(f_path)\n",
        "                if ext_list.count(tip) == 0:\n",
        "                  bad_images.append(f_path)\n",
        "                if os.path.isfile(f_path):\n",
        "                    try:\n",
        "                        img=cv2.imread(f_path)\n",
        "                        shape=img.shape\n",
        "                    except:\n",
        "                        print('file ', f_path, ' is not a valid image file')\n",
        "                        bad_images.append(f_path)\n",
        "                else:\n",
        "                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
        "        else:\n",
        "            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
        "    return bad_images, bad_ext\n",
        "\n",
        "source_dir =r'/content/DatasetV3/Validation'\n",
        "good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
        "bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
        "if len(bad_file_list) !=0:\n",
        "    print('improper image files are listed below')\n",
        "    for i in range (len(bad_file_list)):\n",
        "        print (bad_file_list[i])\n",
        "else:\n",
        "    print(' no improper image files were found')"
      ],
      "metadata": {
        "id": "J5ae_tAbeNaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"Battery\",\"Calculator\",\"Charger\",\"Jumper Wire\",\"LCD Screen\",\"LED\",\"MOSFET\",\"Microcontroller\",\"Resistor\",\"SD Card\",\"USB\"]\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "YYOkI7a0dadz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomBrightness(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2)\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "zM86zDyPcM3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "BK_VVMHBcRXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This model was the first model used to train early versions of the project\n",
        "#This is not ultilized in the final run of the code\n",
        "\n",
        "#num_classes = len(class_names)\n",
        "\n",
        "\n",
        "#model = tf.keras.Sequential([  #Allows layers to be added to the neural network\n",
        "  #tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),  #Rescale values in between 0 and 1\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),                   #Cuts feature map size by 4 times\n",
        "  #tf.keras.layers.BatchNormalization(),\n",
        "  #tf.keras.layers.Activation(\"relu\"),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),#Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Flatten(),        #After learning, flattens the images so that they are 1D\n",
        "  #tf.keras.layers.Dense(128, activation='relu'),    #Only contains neurons, 128 in total\n",
        "  #tf.keras.layers.Dense(num_classes)\n",
        "\n",
        "#]\n",
        "#)\n",
        "\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "8hgO74EFhCUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is an experimental custom written model\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # Entry block\n",
        "    x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [256, 512, 728]:\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Dropout(0.7)(x)\n",
        "    outputs = tf.keras.layers.Dense(11, activation=activation)(x)  #Units must be updated as more categories are added\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "image_size = (img_height, img_width)\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=11)\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "pp_-Y9W2F_UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "frNpjr1fjIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 15\n",
        ")"
      ],
      "metadata": {
        "id": "A-s-d3CJj-LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds,\n",
        ")"
      ],
      "metadata": {
        "id": "dEHOZX0Q0Htz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "eAVECHN7Ecgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "plt.figure(figsize = (15,15))\n",
        "for images, labels in test_ds.take(1):\n",
        "  classifications = model(images)\n",
        "  #print(classifications)\n",
        "\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    index = numpy.argmax(classifications[i])\n",
        "    plt.title(\"Pred: \" + class_names[index] + \" |Real: \" + class_names[labels[i]])"
      ],
      "metadata": {
        "id": "eo7DHH9nFmt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = 15\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FT_x4eCYGYgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "con_mat_df = pd.DataFrame(con_mat_norm,\n",
        "                     index = classes,\n",
        "                     columns = classes)\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N-n0_E8JU7K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model) #convert neural network into TF Lite model\n",
        "tflite_model = converter.convert() #converts model into the proper TF Lite file type\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)  #Write the saved TF lite model into a new file"
      ],
      "metadata": {
        "id": "Q9e5hhOUIZgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}