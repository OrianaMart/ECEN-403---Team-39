{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfbYUeWcjz5H7+0Evz7s/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrianaMart/ECEN-403---Team-39/blob/ML/TEAM39_MLModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6JAYE5jTosp"
      },
      "outputs": [],
      "source": [
        "!unzip Validation.zip #This portion unzips the folder containing the dataset images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf Dataset2/ #This is only to be run when the file needs to be cleared out"
      ],
      "metadata": {
        "id": "DHrFzUciN2Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf    #This section is where all the necessary imports are brought into the project\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RnTrUq9zUoYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 64,64    #Sets constant image size\n",
        "batch_size = 16      #Amount of images to be processed at a given time, the lower the number the easier it is to process\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(          #Set up for the training dataset, takes image directory and turns it into a dataset\n",
        "    \"Dataset2/Training\",                                   #Sets training image directory to training dataset\n",
        "    image_size = (img_height, img_width),                    #Constant image size that matches previously set size\n",
        "    batch_size = batch_size                                       #Constant bach size\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(       #Set up for the validation dataset, takes image directory and turns it into a dataset\n",
        "    \"Dataset2/Validation\",                                    #Sets validation image directory to validation dataset\n",
        "    image_size = (img_height, img_width),                        #Constant image size that matches previously set size\n",
        "    batch_size = batch_size                                              #Constant bach size\n",
        ")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(       #Set up for the testing dataset, takes image directory and turns it into a dataset\n",
        "    \"Dataset2/Testing\",                                       #Sets testing image directory to testing dataset\n",
        "    image_size = (img_height, img_width),                        #Constant image size that matches previously set size\n",
        "    batch_size = batch_size                                     #Constant bach size\n",
        ")"
      ],
      "metadata": {
        "id": "Jf3_3mybU0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "def check_images( s_dir, ext_list):\n",
        "    bad_images=[]\n",
        "    bad_ext=[]\n",
        "    s_list= os.listdir(s_dir)\n",
        "    for klass in s_list:\n",
        "        klass_path=os.path.join (s_dir, klass)\n",
        "        print ('processing class directory ', klass)\n",
        "        if os.path.isdir(klass_path):\n",
        "            file_list=os.listdir(klass_path)\n",
        "            for f in file_list:               \n",
        "                f_path=os.path.join (klass_path,f)\n",
        "                tip = imghdr.what(f_path)\n",
        "                if ext_list.count(tip) == 0:\n",
        "                  bad_images.append(f_path)\n",
        "                if os.path.isfile(f_path):\n",
        "                    try:\n",
        "                        img=cv2.imread(f_path)\n",
        "                        shape=img.shape\n",
        "                    except:\n",
        "                        print('file ', f_path, ' is not a valid image file')\n",
        "                        bad_images.append(f_path)\n",
        "                else:\n",
        "                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
        "        else:\n",
        "            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
        "    return bad_images, bad_ext\n",
        "\n",
        "source_dir =r'/content/Dataset2/Training'\n",
        "good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
        "bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
        "if len(bad_file_list) !=0:\n",
        "    print('improper image files are listed below')\n",
        "    for i in range (len(bad_file_list)):\n",
        "        print (bad_file_list[i])\n",
        "else:\n",
        "    print(' no improper image files were found')"
      ],
      "metadata": {
        "id": "J5ae_tAbeNaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"Calculator\", \"Charger\", \"MOSFET\", \"Microcontroller\"]\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "YYOkI7a0dadz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "zM86zDyPcM3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "BK_VVMHBcRXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This model was the first model used to train early versions of the project\n",
        "#This is not ultilized in the final run of the code\n",
        "\n",
        "#num_classes = len(class_names)\n",
        "\n",
        "\n",
        "#model = tf.keras.Sequential([  #Allows layers to be added to the neural network\n",
        "  #tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),  #Rescale values in between 0 and 1\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),                   #Cuts feature map size by 4 times\n",
        "  #tf.keras.layers.BatchNormalization(),\n",
        "  #tf.keras.layers.Activation(\"relu\"),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),#Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'), #Convolutional layer\n",
        "  #tf.keras.layers.MaxPooling2D(),\n",
        "  #tf.keras.layers.Flatten(),        #After learning, flattens the images so that they are 1D\n",
        "  #tf.keras.layers.Dense(128, activation='relu'),    #Only contains neurons, 128 in total\n",
        "  #tf.keras.layers.Dense(num_classes)\n",
        "  \n",
        "#]\n",
        "#)\n",
        "\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "8hgO74EFhCUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is an experimental custom written model\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "   \n",
        "\n",
        "    # Entry block\n",
        "    x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [256, 512, 728]:\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "  \n",
        "\n",
        "    x = tf.keras.layers.Dropout(0.7)(x)\n",
        "    outputs = tf.keras.layers.Dense(4, activation=activation)(x)  #Units must be updated as more categories are added\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "image_size = (img_height, img_width)\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=4)\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "pp_-Y9W2F_UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "frNpjr1fjIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 15\n",
        ")"
      ],
      "metadata": {
        "id": "A-s-d3CJj-LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "eAVECHN7Ecgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "plt.figure(figsize = (15,15))\n",
        "for images, labels in test_ds.take(1):\n",
        "  classifications = model(images)\n",
        "  #print(classifications)\n",
        "\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    index = numpy.argmax(classifications[i])\n",
        "    plt.title(\"Pred: \" + class_names[index] + \" |Real: \" + class_names[labels[i]])"
      ],
      "metadata": {
        "id": "eo7DHH9nFmt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = 15\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FT_x4eCYGYgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model) #convert neural network into TF Lite model\n",
        "tflite_model = converter.convert() #converts model into the proper TF Lite file type\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)  #Write the saved TF lite model into a new file"
      ],
      "metadata": {
        "id": "Q9e5hhOUIZgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}